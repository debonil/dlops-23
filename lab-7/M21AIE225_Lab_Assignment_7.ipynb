{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "q4R27LUsggPN"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn\n",
        "import torch.optim\n",
        "import torch.utils.data\n",
        "import torchvision.datasets\n",
        "import torchvision.models\n",
        "import torchvision.transforms as T\n",
        "from sklearn import metrics\n",
        "import seaborn as sns\n",
        "import time\n",
        "import math\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vcFTwuyPgjt3",
        "outputId": "e403d2e1-31ad-4707-b7bf-3b7f39fb6f61"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H87KoAc_grpn",
        "outputId": "cd296151-1497-4129-cdbc-9a6aa94f5877"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "transform = T.Compose(\n",
        "    [T.Resize(224),\n",
        "     T.ToTensor(),\n",
        "     T.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "train_set = torchvision.datasets.CIFAR10(\n",
        "    root='./data', train=True, download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(\n",
        "    train_set, batch_size=32, shuffle=True)\n",
        "test_set = torchvision.datasets.CIFAR10(\n",
        "    root='./data', train=False, download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(\n",
        "    test_set, batch_size=32, shuffle=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "9iciG2lYhZBN"
      },
      "outputs": [],
      "source": [
        "def get_model_mobilenet_cifar10():\n",
        "    model = torchvision.models.mobilenet_v2(\n",
        "        weights=torchvision.models.MobileNet_V2_Weights.IMAGENET1K_V2)\n",
        "    model.classifier[1] = torch.nn.Linear(model.classifier[1].in_features, 10)\n",
        "    model = model.to(device)\n",
        "    # print(model)\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "s8VjBfg6i5Vb"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import math\n",
        "\n",
        "\n",
        "def timeSince(since):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "N8m84pXkiuoq"
      },
      "outputs": [],
      "source": [
        "# Train the model\n",
        "def model_training(model, criterion, optimizer, trainloader, testloader, num_epochs=10):\n",
        "    start = time.time()\n",
        "    loss_list = []\n",
        "    for epoch in range(num_epochs):\n",
        "        train_loss = 0.0\n",
        "        val_loss = 0.0\n",
        "        train_acc = 0.0\n",
        "        val_acc = 0.0\n",
        "        for images, labels in trainloader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            # Forward pass\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # Backward and optimize\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "            train_acc += metrics.accuracy_score(labels.cpu().detach(\n",
        "            ).numpy(), outputs.cpu().detach().numpy().argmax(axis=1))\n",
        "        # Evaluate the model on the validation set\n",
        "        with torch.no_grad():\n",
        "            for images, labels in testloader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "                val_loss += loss.item()\n",
        "                val_acc += metrics.accuracy_score(labels.cpu().detach(\n",
        "                ).numpy(), outputs.cpu().detach().numpy().argmax(axis=1))\n",
        "        train_loss = train_loss/len(trainloader)\n",
        "        val_loss = val_loss/len(testloader)\n",
        "        train_acc = train_acc/len(trainloader)\n",
        "        val_acc = val_acc/len(testloader)\n",
        "        print(f'Epoch: {epoch+1} ({timeSince(start)}) \\tTraining Loss: {train_loss:.3f}, \\tTest Loss: {val_loss:.3f},  \\tTraining acc: {train_acc:.2f}, \\tTest acc: {val_acc:.2f}, ')\n",
        "        loss_list.append([train_loss, val_loss, train_acc, val_acc])\n",
        "\n",
        "    print(\n",
        "        f'Training completed in {timeSince(start)} \\tTraining Loss: {loss_list[-1][0]:.3f}, \\tTest Loss: {loss_list[-1][1]:.3f},  \\tTraining acc: {loss_list[-1][2]:.2f}, \\tTest acc: {loss_list[-1][3]:.2f}, ')\n",
        "    return np.array(loss_list), time.time()-start, loss_list[-1][2], loss_list[-1][3]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "A33ArbuUk68S"
      },
      "outputs": [],
      "source": [
        "from sklearn import metrics\n",
        "import seaborn as sns\n",
        "#sns.set(rc={'axes.facecolor': 'lightblue', 'figure.facecolor': 'lightblue'})\n",
        "\n",
        "\n",
        "def confusionMatrixAndAccuracyReport(Y_test, Y_pred_probs, label):\n",
        "    Y_pred = Y_pred_probs.argmax(axis=1)\n",
        "    cm = metrics.confusion_matrix(Y_test, Y_pred)\n",
        "    overallAccuracy = metrics.accuracy_score(Y_test, Y_pred)\n",
        "\n",
        "    classwiseAccuracy = cm.diagonal()/cm.sum(axis=1)\n",
        "\n",
        "    top_5_accuracy = metrics.top_k_accuracy_score(\n",
        "        Y_test, Y_pred_probs, k=5, labels=np.arange(10))\n",
        "\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    plt.title(\n",
        "        f'Top 1 Accuracy : {overallAccuracy*100:3.2f}% | Top 5 Accuracy : {top_5_accuracy*100:3.2f}% ', size=14)\n",
        "    plt.ylabel('Actual label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    sns.heatmap(data=cm, annot=True, square=True,  cmap='Blues', fmt='g')\n",
        "\n",
        "    plt.show()\n",
        "    print(f'Top 1 Accuracy: {overallAccuracy*100:3.3f}%')\n",
        "    print(f'Top 5 Accuracy: {top_5_accuracy*100}%')\n",
        "    print(f'Classwise Accuracy Score: \\n{classwiseAccuracy}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "DKkLoRgVlKWU"
      },
      "outputs": [],
      "source": [
        "def plot_training_graphs(loss_list):\n",
        "    fig = plt.figure(figsize=(20, 7))\n",
        "    plot = fig.add_subplot(1, 2, 1)\n",
        "    plot.set_title(\"Training vs Validation loss\")\n",
        "    plot.plot(loss_list[:, 0], linestyle='--', label=\"Training Loss\")\n",
        "    plot.plot(loss_list[:, 1], linestyle='-', label=\"Validation Loss\")\n",
        "    plot.set_xlabel(\"Epoch\")\n",
        "    plot.set_ylabel(\"Loss\")\n",
        "    plot.legend()\n",
        "    plot = fig.add_subplot(1, 2, 2)\n",
        "    plot.set_title(\"Training vs Validation Accuracy\")\n",
        "    plot.plot(loss_list[:, 2], linestyle='--', label=\"Training Accuracy\")\n",
        "    plot.plot(loss_list[:, 3], linestyle='-', label=\"Validation Accuracy\")\n",
        "    plot.set_xlabel(\"Epoch\")\n",
        "    plot.set_ylabel(\"Accuracy\")\n",
        "    plot.legend()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oGXCqSmXq5jh"
      },
      "outputs": [],
      "source": [
        "learning_rates = [1e-2, 1e-3, 1e-4, 1e-5, 1e-6]\n",
        "num_epochs = [10, 15]\n",
        "\n",
        "results = []\n",
        "\n",
        "for lr in learning_rates:\n",
        "    for epoch in num_epochs:\n",
        "        print(\n",
        "            f'\\n\\n***\\t\\t\\t\\tEpoch = {epoch}\\tLearning Rate = {lr}\\t\\t\\t\\t***\\n\\n')\n",
        "        model = get_model_mobilenet_cifar10()\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "        criterion = torch.nn.CrossEntropyLoss()\n",
        "        loss_list, t, train_a, test_a = model_training(\n",
        "            model, criterion, optimizer, trainloader, testloader, num_epochs=epoch)\n",
        "        results.append({\n",
        "            \"Learning Rate\": lr,\n",
        "            \"Epoch\": epoch,\n",
        "            \"Training Time\": t,\n",
        "            \"Training Accuracy\": train_a,\n",
        "            \"Test Accuracy\": test_a,\n",
        "        })\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yJg8kO8gvnjS"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame(results)\n",
        "print(\"\\n\\n Overall Summary : \\n\")\n",
        "print(df.to_markdown(index=False))\n",
        "df.to_csv(\"M21AIE225_lab_7_summary.csv\", index=False)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
