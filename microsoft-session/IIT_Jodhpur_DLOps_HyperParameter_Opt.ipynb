{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t2gnPC6xFiV3",
        "outputId": "ccb0c4a4-3fce-4d27-a2ff-3db973f4e889"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: optuna in /usr/local/lib/python3.9/dist-packages (3.1.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.9/dist-packages (from optuna) (6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from optuna) (23.0)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.9/dist-packages (from optuna) (1.10.3)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.9/dist-packages (from optuna) (6.7.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from optuna) (1.22.4)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.9/dist-packages (from optuna) (2.0.9)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from optuna) (4.65.0)\n",
            "Requirement already satisfied: cmaes>=0.9.1 in /usr/local/lib/python3.9/dist-packages (from optuna) (0.9.1)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.9/dist-packages (from alembic>=1.5.0->optuna) (1.2.4)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.9/dist-packages (from alembic>=1.5.0->optuna) (4.5.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.9/dist-packages (from sqlalchemy>=1.3.0->optuna) (2.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.9/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.2)\n"
          ]
        }
      ],
      "source": [
        "%pip install optuna # hyperopt, sigopt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "import optuna\n",
        "from optuna.trial import TrialState\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "\n",
        "\n",
        "DEVICE = torch.device(\"cpu\")\n",
        "BATCHSIZE = 128\n",
        "CLASSES = 10\n",
        "DIR = os.getcwd()\n",
        "EPOCHS = 10\n",
        "N_TRAIN_EXAMPLES = BATCHSIZE * 30\n",
        "N_VALID_EXAMPLES = BATCHSIZE * 10"
      ],
      "metadata": {
        "id": "k-2WIo0UFpnS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# n_layers: 1-3 \n",
        "# n_nodes: 4-128\n",
        "# doprout: 0.2, 0.3, 0.4, 0.5\n",
        "# optimizer: [\"Adam\", \"RMSprop\", \"SGD\"]\n",
        "# lr: e-5, e-4, e-3, e-2, e-1\n",
        "\n",
        "3 * 125 * 4 * 3 * 5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rMY6w-lsEnEf",
        "outputId": "143b4937-3745-4df1-bbdd-4cca1e7669d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "22500"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def define_model(trial):\n",
        "    # We optimize the number of layers, hidden units and dropout ratio in each layer.\n",
        "    n_layers = trial.suggest_int(\"n_layers\", 1, 3)\n",
        "    layers = []\n",
        "\n",
        "    in_features = 28 * 28\n",
        "    for i in range(n_layers):\n",
        "        out_features = trial.suggest_int(\"n_units_l{}\".format(i), 4, 128)\n",
        "        layers.append(nn.Linear(in_features, out_features))\n",
        "        layers.append(nn.ReLU())\n",
        "        p = trial.suggest_float(\"dropout_l{}\".format(i), 0.2, 0.5)\n",
        "        layers.append(nn.Dropout(p))\n",
        "\n",
        "        in_features = out_features\n",
        "    layers.append(nn.Linear(in_features, CLASSES))\n",
        "    layers.append(nn.LogSoftmax(dim=1))\n",
        "\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "\n",
        "def get_mnist():\n",
        "    # Load FashionMNIST dataset.\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        datasets.FashionMNIST(DIR, train=True, download=True, transform=transforms.ToTensor()),\n",
        "        batch_size=BATCHSIZE,\n",
        "        shuffle=True,\n",
        "    )\n",
        "    valid_loader = torch.utils.data.DataLoader(\n",
        "        datasets.FashionMNIST(DIR, train=False, transform=transforms.ToTensor()),\n",
        "        batch_size=BATCHSIZE,\n",
        "        shuffle=True,\n",
        "    )\n",
        "\n",
        "    return train_loader, valid_loader\n",
        "\n",
        "\n",
        "def objective(trial):\n",
        "    # Generate the model.\n",
        "    model = define_model(trial).to(DEVICE)\n",
        "\n",
        "    # Generate the optimizers.\n",
        "    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"RMSprop\", \"SGD\"])\n",
        "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-1, log=True)\n",
        "    optimizer = getattr(optim, optimizer_name)(model.parameters(), lr=lr)\n",
        "\n",
        "    # Get the FashionMNIST dataset.\n",
        "    train_loader, valid_loader = get_mnist()\n",
        "\n",
        "    # Training of the model.\n",
        "    for epoch in range(EPOCHS):\n",
        "        model.train()\n",
        "        for batch_idx, (data, target) in enumerate(train_loader):\n",
        "            # Limiting training data for faster epochs.\n",
        "            if batch_idx * BATCHSIZE >= N_TRAIN_EXAMPLES:\n",
        "                break\n",
        "\n",
        "            data, target = data.view(data.size(0), -1).to(DEVICE), target.to(DEVICE)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "            loss = F.nll_loss(output, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        # Validation of the model.\n",
        "        model.eval()\n",
        "        correct = 0\n",
        "        with torch.no_grad():\n",
        "            for batch_idx, (data, target) in enumerate(valid_loader):\n",
        "                # Limiting validation data.\n",
        "                if batch_idx * BATCHSIZE >= N_VALID_EXAMPLES:\n",
        "                    break\n",
        "                data, target = data.view(data.size(0), -1).to(DEVICE), target.to(DEVICE)\n",
        "                output = model(data)\n",
        "                # Get the index of the max log-probability.\n",
        "                pred = output.argmax(dim=1, keepdim=True)\n",
        "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "        accuracy = correct / min(len(valid_loader.dataset), N_VALID_EXAMPLES)\n",
        "\n",
        "        trial.report(accuracy, epoch)\n",
        "\n",
        "        # Handle pruning based on the intermediate value.\n",
        "        if trial.should_prune():\n",
        "            raise optuna.exceptions.TrialPruned()\n",
        "\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "4HqvMKVqFswT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "study = optuna.create_study(direction=\"maximize\")\n",
        "study.optimize(objective, n_trials=100, timeout=600)\n",
        "\n",
        "pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
        "complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
        "\n",
        "print(\"Study statistics: \")\n",
        "print(\"  Number of finished trials: \", len(study.trials))\n",
        "print(\"  Number of pruned trials: \", len(pruned_trials))\n",
        "print(\"  Number of complete trials: \", len(complete_trials))\n",
        "\n",
        "print(\"Best trial:\")\n",
        "trial = study.best_trial\n",
        "\n",
        "print(\"  Value: \", trial.value)\n",
        "\n",
        "print(\"  Params: \")\n",
        "for key, value in trial.params.items():\n",
        "  print(\"    {}: {}\".format(key, value))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o9p8uzT6Fu4o",
        "outputId": "e455a5ce-66ae-40d2-90fc-e8d7daaa3f33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-04-15 04:04:12,559]\u001b[0m A new study created in memory with name: no-name-cabf4d0f-4635-4116-8bc5-9cf7630070b1\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to /content/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26421880/26421880 [00:00<00:00, 116857064.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /content/FashionMNIST/raw/train-images-idx3-ubyte.gz to /content/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to /content/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29515/29515 [00:00<00:00, 4457221.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /content/FashionMNIST/raw/train-labels-idx1-ubyte.gz to /content/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to /content/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4422102/4422102 [00:00<00:00, 65765476.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /content/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to /content/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to /content/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5148/5148 [00:00<00:00, 9918363.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /content/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to /content/FashionMNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-04-15 04:04:25,826]\u001b[0m Trial 0 finished with value: 0.08203125 and parameters: {'n_layers': 3, 'n_units_l0': 22, 'dropout_l0': 0.4956077789646988, 'n_units_l1': 102, 'dropout_l1': 0.2207862356370877, 'n_units_l2': 79, 'dropout_l2': 0.45346857822886527, 'optimizer': 'SGD', 'lr': 1.1733925141599031e-05}. Best is trial 0 with value: 0.08203125.\u001b[0m\n",
            "\u001b[32m[I 2023-04-15 04:04:35,644]\u001b[0m Trial 1 finished with value: 0.1109375 and parameters: {'n_layers': 1, 'n_units_l0': 56, 'dropout_l0': 0.33420592376376, 'optimizer': 'SGD', 'lr': 2.4765562066111482e-05}. Best is trial 1 with value: 0.1109375.\u001b[0m\n",
            "\u001b[32m[I 2023-04-15 04:04:43,788]\u001b[0m Trial 2 finished with value: 0.23125 and parameters: {'n_layers': 1, 'n_units_l0': 16, 'dropout_l0': 0.48952548904965953, 'optimizer': 'Adam', 'lr': 1.3181966788600786e-05}. Best is trial 2 with value: 0.23125.\u001b[0m\n",
            "\u001b[32m[I 2023-04-15 04:04:52,346]\u001b[0m Trial 3 finished with value: 0.76953125 and parameters: {'n_layers': 1, 'n_units_l0': 19, 'dropout_l0': 0.489089118432106, 'optimizer': 'Adam', 'lr': 0.0015567723971709497}. Best is trial 3 with value: 0.76953125.\u001b[0m\n",
            "\u001b[32m[I 2023-04-15 04:05:00,210]\u001b[0m Trial 4 finished with value: 0.75625 and parameters: {'n_layers': 1, 'n_units_l0': 55, 'dropout_l0': 0.4067556143577415, 'optimizer': 'RMSprop', 'lr': 0.02229725406111942}. Best is trial 3 with value: 0.76953125.\u001b[0m\n",
            "\u001b[32m[I 2023-04-15 04:05:09,553]\u001b[0m Trial 5 finished with value: 0.64140625 and parameters: {'n_layers': 2, 'n_units_l0': 91, 'dropout_l0': 0.20452079158459036, 'n_units_l1': 79, 'dropout_l1': 0.41921172915828714, 'optimizer': 'RMSprop', 'lr': 5.088619751204677e-05}. Best is trial 3 with value: 0.76953125.\u001b[0m\n",
            "\u001b[32m[I 2023-04-15 04:05:18,253]\u001b[0m Trial 6 finished with value: 0.77421875 and parameters: {'n_layers': 2, 'n_units_l0': 37, 'dropout_l0': 0.47109024112703535, 'n_units_l1': 102, 'dropout_l1': 0.26845865579698974, 'optimizer': 'RMSprop', 'lr': 0.0016241018936645492}. Best is trial 6 with value: 0.77421875.\u001b[0m\n",
            "\u001b[32m[I 2023-04-15 04:05:19,125]\u001b[0m Trial 7 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-04-15 04:05:19,989]\u001b[0m Trial 8 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-04-15 04:05:20,811]\u001b[0m Trial 9 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-04-15 04:05:30,443]\u001b[0m Trial 10 finished with value: 0.67890625 and parameters: {'n_layers': 2, 'n_units_l0': 84, 'dropout_l0': 0.4432934823887463, 'n_units_l1': 25, 'dropout_l1': 0.2662430627713772, 'optimizer': 'RMSprop', 'lr': 0.007625481403442797}. Best is trial 6 with value: 0.77421875.\u001b[0m\n",
            "\u001b[32m[I 2023-04-15 04:05:39,242]\u001b[0m Trial 11 finished with value: 0.71171875 and parameters: {'n_layers': 2, 'n_units_l0': 37, 'dropout_l0': 0.4970635802536184, 'n_units_l1': 40, 'dropout_l1': 0.30711874589793, 'optimizer': 'Adam', 'lr': 0.001277019778638216}. Best is trial 6 with value: 0.77421875.\u001b[0m\n",
            "\u001b[32m[I 2023-04-15 04:05:40,670]\u001b[0m Trial 12 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-04-15 04:05:41,530]\u001b[0m Trial 13 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-04-15 04:05:43,314]\u001b[0m Trial 14 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-04-15 04:05:51,768]\u001b[0m Trial 15 finished with value: 0.77421875 and parameters: {'n_layers': 1, 'n_units_l0': 47, 'dropout_l0': 0.46742016621804955, 'optimizer': 'Adam', 'lr': 0.004109716062869709}. Best is trial 6 with value: 0.77421875.\u001b[0m\n",
            "\u001b[32m[I 2023-04-15 04:05:53,168]\u001b[0m Trial 16 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-04-15 04:06:01,796]\u001b[0m Trial 17 finished with value: 0.80390625 and parameters: {'n_layers': 2, 'n_units_l0': 79, 'dropout_l0': 0.4187433097600335, 'n_units_l1': 105, 'dropout_l1': 0.26552612983962576, 'optimizer': 'Adam', 'lr': 0.014889471012274785}. Best is trial 17 with value: 0.80390625.\u001b[0m\n",
            "\u001b[32m[I 2023-04-15 04:06:02,745]\u001b[0m Trial 18 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-04-15 04:06:03,798]\u001b[0m Trial 19 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-04-15 04:06:14,061]\u001b[0m Trial 20 finished with value: 0.7640625 and parameters: {'n_layers': 2, 'n_units_l0': 81, 'dropout_l0': 0.41938090342437506, 'n_units_l1': 70, 'dropout_l1': 0.3288274142343222, 'optimizer': 'Adam', 'lr': 0.01696320178361401}. Best is trial 17 with value: 0.80390625.\u001b[0m\n",
            "\u001b[32m[I 2023-04-15 04:06:23,276]\u001b[0m Trial 21 finished with value: 0.77734375 and parameters: {'n_layers': 2, 'n_units_l0': 50, 'dropout_l0': 0.4635167391229811, 'n_units_l1': 112, 'dropout_l1': 0.2412272760841393, 'optimizer': 'Adam', 'lr': 0.0034280773003836696}. Best is trial 17 with value: 0.80390625.\u001b[0m\n",
            "\u001b[32m[I 2023-04-15 04:06:32,785]\u001b[0m Trial 22 finished with value: 0.8328125 and parameters: {'n_layers': 2, 'n_units_l0': 99, 'dropout_l0': 0.468716760675418, 'n_units_l1': 114, 'dropout_l1': 0.2500345068894881, 'optimizer': 'Adam', 'lr': 0.002737201755182192}. Best is trial 22 with value: 0.8328125.\u001b[0m\n",
            "\u001b[32m[I 2023-04-15 04:06:41,357]\u001b[0m Trial 23 finished with value: 0.83046875 and parameters: {'n_layers': 2, 'n_units_l0': 98, 'dropout_l0': 0.4396892482027989, 'n_units_l1': 120, 'dropout_l1': 0.22502568081922386, 'optimizer': 'Adam', 'lr': 0.003149064475474711}. Best is trial 22 with value: 0.8328125.\u001b[0m\n",
            "\u001b[32m[I 2023-04-15 04:06:42,656]\u001b[0m Trial 24 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-04-15 04:06:45,115]\u001b[0m Trial 25 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-04-15 04:06:46,901]\u001b[0m Trial 26 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-04-15 04:06:47,876]\u001b[0m Trial 27 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-04-15 04:06:57,653]\u001b[0m Trial 28 finished with value: 0.78359375 and parameters: {'n_layers': 2, 'n_units_l0': 116, 'dropout_l0': 0.4672118822900269, 'n_units_l1': 128, 'dropout_l1': 0.2503471318842878, 'optimizer': 'Adam', 'lr': 0.00818407416593181}. Best is trial 22 with value: 0.8328125.\u001b[0m\n",
            "\u001b[32m[I 2023-04-15 04:06:58,560]\u001b[0m Trial 29 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-04-15 04:07:10,559]\u001b[0m Trial 30 finished with value: 0.7890625 and parameters: {'n_layers': 3, 'n_units_l0': 91, 'dropout_l0': 0.4312803951807028, 'n_units_l1': 70, 'dropout_l1': 0.2847320530682925, 'n_units_l2': 48, 'dropout_l2': 0.2854967087592087, 'optimizer': 'Adam', 'lr': 0.010067552264149371}. Best is trial 22 with value: 0.8328125.\u001b[0m\n",
            "\u001b[32m[I 2023-04-15 04:07:12,456]\u001b[0m Trial 31 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-04-15 04:07:13,466]\u001b[0m Trial 32 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-04-15 04:07:24,096]\u001b[0m Trial 33 finished with value: 0.7765625 and parameters: {'n_layers': 2, 'n_units_l0': 62, 'dropout_l0': 0.455922453076855, 'n_units_l1': 74, 'dropout_l1': 0.2318015683029237, 'optimizer': 'Adam', 'lr': 0.002209200837907139}. Best is trial 22 with value: 0.8328125.\u001b[0m\n",
            "\u001b[32m[I 2023-04-15 04:07:32,788]\u001b[0m Trial 34 finished with value: 0.7640625 and parameters: {'n_layers': 2, 'n_units_l0': 110, 'dropout_l0': 0.48022258506466303, 'n_units_l1': 91, 'dropout_l1': 0.27216711291072754, 'optimizer': 'Adam', 'lr': 0.010324207338419768}. Best is trial 22 with value: 0.8328125.\u001b[0m\n",
            "\u001b[32m[I 2023-04-15 04:07:33,801]\u001b[0m Trial 35 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-04-15 04:07:42,963]\u001b[0m Trial 36 finished with value: 0.81796875 and parameters: {'n_layers': 1, 'n_units_l0': 75, 'dropout_l0': 0.44019845095100435, 'optimizer': 'Adam', 'lr': 0.002078191200015793}. Best is trial 22 with value: 0.8328125.\u001b[0m\n",
            "\u001b[32m[I 2023-04-15 04:07:52,292]\u001b[0m Trial 37 finished with value: 0.7921875 and parameters: {'n_layers': 1, 'n_units_l0': 75, 'dropout_l0': 0.4789968342557633, 'optimizer': 'Adam', 'lr': 0.002429056287838167}. Best is trial 22 with value: 0.8328125.\u001b[0m\n",
            "\u001b[32m[I 2023-04-15 04:07:54,006]\u001b[0m Trial 38 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-04-15 04:08:03,773]\u001b[0m Trial 39 finished with value: 0.790625 and parameters: {'n_layers': 1, 'n_units_l0': 83, 'dropout_l0': 0.4827874520697104, 'optimizer': 'Adam', 'lr': 0.0018567301122324703}. Best is trial 22 with value: 0.8328125.\u001b[0m\n",
            "\u001b[32m[I 2023-04-15 04:08:04,633]\u001b[0m Trial 40 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-04-15 04:08:13,338]\u001b[0m Trial 41 finished with value: 0.81796875 and parameters: {'n_layers': 1, 'n_units_l0': 75, 'dropout_l0': 0.4796510711281343, 'optimizer': 'Adam', 'lr': 0.0026548883959724634}. Best is trial 22 with value: 0.8328125.\u001b[0m\n",
            "\u001b[32m[I 2023-04-15 04:08:22,216]\u001b[0m Trial 42 finished with value: 0.83828125 and parameters: {'n_layers': 1, 'n_units_l0': 86, 'dropout_l0': 0.46656652538027943, 'optimizer': 'Adam', 'lr': 0.0029311440561004105}. Best is trial 42 with value: 0.83828125.\u001b[0m\n",
            "\u001b[32m[I 2023-04-15 04:08:32,495]\u001b[0m Trial 43 finished with value: 0.8375 and parameters: {'n_layers': 1, 'n_units_l0': 88, 'dropout_l0': 0.4940887896161883, 'optimizer': 'Adam', 'lr': 0.0025103798501833643}. Best is trial 42 with value: 0.83828125.\u001b[0m\n",
            "\u001b[32m[I 2023-04-15 04:08:33,462]\u001b[0m Trial 44 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-04-15 04:08:42,955]\u001b[0m Trial 45 finished with value: 0.82421875 and parameters: {'n_layers': 1, 'n_units_l0': 97, 'dropout_l0': 0.4585692434376335, 'optimizer': 'Adam', 'lr': 0.0017208244890203513}. Best is trial 42 with value: 0.83828125.\u001b[0m\n",
            "\u001b[32m[I 2023-04-15 04:08:51,288]\u001b[0m Trial 46 finished with value: 0.81640625 and parameters: {'n_layers': 1, 'n_units_l0': 98, 'dropout_l0': 0.49154558037628615, 'optimizer': 'Adam', 'lr': 0.0014654888834423475}. Best is trial 42 with value: 0.83828125.\u001b[0m\n",
            "\u001b[32m[I 2023-04-15 04:09:00,542]\u001b[0m Trial 47 finished with value: 0.8234375 and parameters: {'n_layers': 1, 'n_units_l0': 113, 'dropout_l0': 0.46480216123136875, 'optimizer': 'Adam', 'lr': 0.0036267548518590675}. Best is trial 42 with value: 0.83828125.\u001b[0m\n",
            "\u001b[32m[I 2023-04-15 04:09:01,457]\u001b[0m Trial 48 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-04-15 04:09:03,113]\u001b[0m Trial 49 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-04-15 04:09:04,039]\u001b[0m Trial 50 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-04-15 04:09:13,419]\u001b[0m Trial 51 finished with value: 0.81796875 and parameters: {'n_layers': 1, 'n_units_l0': 113, 'dropout_l0': 0.46321242494711923, 'optimizer': 'Adam', 'lr': 0.0032895496230066993}. Best is trial 42 with value: 0.83828125.\u001b[0m\n",
            "\u001b[32m[I 2023-04-15 04:09:22,908]\u001b[0m Trial 52 finished with value: 0.82265625 and parameters: {'n_layers': 1, 'n_units_l0': 128, 'dropout_l0': 0.44553487033908296, 'optimizer': 'Adam', 'lr': 0.0026731508909853276}. Best is trial 42 with value: 0.83828125.\u001b[0m\n",
            "\u001b[32m[I 2023-04-15 04:09:32,189]\u001b[0m Trial 53 finished with value: 0.81484375 and parameters: {'n_layers': 1, 'n_units_l0': 105, 'dropout_l0': 0.47215281140471704, 'optimizer': 'Adam', 'lr': 0.005888631889893845}. Best is trial 42 with value: 0.83828125.\u001b[0m\n",
            "\u001b[32m[I 2023-04-15 04:09:41,737]\u001b[0m Trial 54 finished with value: 0.81328125 and parameters: {'n_layers': 1, 'n_units_l0': 112, 'dropout_l0': 0.4874229383191366, 'optimizer': 'Adam', 'lr': 0.00437139582971842}. Best is trial 42 with value: 0.83828125.\u001b[0m\n",
            "\u001b[32m[I 2023-04-15 04:09:42,864]\u001b[0m Trial 55 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-04-15 04:09:44,102]\u001b[0m Trial 56 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-04-15 04:09:52,450]\u001b[0m Trial 57 finished with value: 0.8078125 and parameters: {'n_layers': 1, 'n_units_l0': 108, 'dropout_l0': 0.47316955677432515, 'optimizer': 'RMSprop', 'lr': 0.0033528667385360573}. Best is trial 42 with value: 0.83828125.\u001b[0m\n",
            "\u001b[32m[I 2023-04-15 04:09:53,432]\u001b[0m Trial 58 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-04-15 04:09:54,364]\u001b[0m Trial 59 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-04-15 04:09:55,479]\u001b[0m Trial 60 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-04-15 04:10:04,772]\u001b[0m Trial 61 finished with value: 0.8328125 and parameters: {'n_layers': 1, 'n_units_l0': 128, 'dropout_l0': 0.44701373640321534, 'optimizer': 'Adam', 'lr': 0.002700296703486166}. Best is trial 42 with value: 0.83828125.\u001b[0m\n",
            "\u001b[32m[I 2023-04-15 04:10:06,529]\u001b[0m Trial 62 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-04-15 04:10:16,042]\u001b[0m Trial 63 finished with value: 0.81171875 and parameters: {'n_layers': 1, 'n_units_l0': 112, 'dropout_l0': 0.4705755146417528, 'optimizer': 'Adam', 'lr': 0.0029420927438078624}. Best is trial 42 with value: 0.83828125.\u001b[0m\n",
            "\u001b[32m[I 2023-04-15 04:10:25,331]\u001b[0m Trial 64 finished with value: 0.8265625 and parameters: {'n_layers': 1, 'n_units_l0': 118, 'dropout_l0': 0.4365308695517364, 'optimizer': 'Adam', 'lr': 0.0036527651659816526}. Best is trial 42 with value: 0.83828125.\u001b[0m\n",
            "\u001b[32m[I 2023-04-15 04:10:34,157]\u001b[0m Trial 65 finished with value: 0.8328125 and parameters: {'n_layers': 1, 'n_units_l0': 120, 'dropout_l0': 0.4324276503505859, 'optimizer': 'Adam', 'lr': 0.0022461928707783857}. Best is trial 42 with value: 0.83828125.\u001b[0m\n",
            "\u001b[32m[I 2023-04-15 04:10:35,551]\u001b[0m Trial 66 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-04-15 04:10:38,242]\u001b[0m Trial 67 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-04-15 04:10:48,233]\u001b[0m Trial 68 finished with value: 0.82109375 and parameters: {'n_layers': 1, 'n_units_l0': 124, 'dropout_l0': 0.42933253328199206, 'optimizer': 'Adam', 'lr': 0.002363336306864824}. Best is trial 42 with value: 0.83828125.\u001b[0m\n",
            "\u001b[32m[I 2023-04-15 04:10:49,421]\u001b[0m Trial 69 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-04-15 04:10:50,316]\u001b[0m Trial 70 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-04-15 04:10:51,251]\u001b[0m Trial 71 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-04-15 04:10:52,189]\u001b[0m Trial 72 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-04-15 04:10:53,136]\u001b[0m Trial 73 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-04-15 04:10:54,915]\u001b[0m Trial 74 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-04-15 04:11:03,691]\u001b[0m Trial 75 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-04-15 04:11:12,416]\u001b[0m Trial 76 finished with value: 0.8046875 and parameters: {'n_layers': 1, 'n_units_l0': 88, 'dropout_l0': 0.4259056533606791, 'optimizer': 'Adam', 'lr': 0.008257989898792943}. Best is trial 42 with value: 0.83828125.\u001b[0m\n",
            "\u001b[32m[I 2023-04-15 04:11:21,603]\u001b[0m Trial 77 finished with value: 0.809375 and parameters: {'n_layers': 1, 'n_units_l0': 122, 'dropout_l0': 0.4394660224066994, 'optimizer': 'Adam', 'lr': 0.002263002349744444}. Best is trial 42 with value: 0.83828125.\u001b[0m\n",
            "\u001b[32m[I 2023-04-15 04:11:31,002]\u001b[0m Trial 78 finished with value: 0.8234375 and parameters: {'n_layers': 1, 'n_units_l0': 102, 'dropout_l0': 0.44707861524453824, 'optimizer': 'Adam', 'lr': 0.0037775600869314634}. Best is trial 42 with value: 0.83828125.\u001b[0m\n",
            "\u001b[32m[I 2023-04-15 04:11:31,954]\u001b[0m Trial 79 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-04-15 04:11:42,071]\u001b[0m Trial 80 finished with value: 0.79765625 and parameters: {'n_layers': 1, 'n_units_l0': 126, 'dropout_l0': 0.4125316794603593, 'optimizer': 'Adam', 'lr': 0.005638896934488105}. Best is trial 42 with value: 0.83828125.\u001b[0m\n",
            "\u001b[32m[I 2023-04-15 04:11:43,031]\u001b[0m Trial 81 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-04-15 04:11:53,317]\u001b[0m Trial 82 finished with value: 0.81015625 and parameters: {'n_layers': 1, 'n_units_l0': 114, 'dropout_l0': 0.46239256089061415, 'optimizer': 'Adam', 'lr': 0.0029438484891785963}. Best is trial 42 with value: 0.83828125.\u001b[0m\n",
            "\u001b[32m[I 2023-04-15 04:11:54,918]\u001b[0m Trial 83 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-04-15 04:12:03,563]\u001b[0m Trial 84 finished with value: 0.8109375 and parameters: {'n_layers': 1, 'n_units_l0': 99, 'dropout_l0': 0.4580476892552895, 'optimizer': 'Adam', 'lr': 0.0037908598057303407}. Best is trial 42 with value: 0.83828125.\u001b[0m\n",
            "\u001b[32m[I 2023-04-15 04:12:04,513]\u001b[0m Trial 85 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-04-15 04:12:05,705]\u001b[0m Trial 86 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-04-15 04:12:06,972]\u001b[0m Trial 87 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-04-15 04:12:15,703]\u001b[0m Trial 88 finished with value: 0.81796875 and parameters: {'n_layers': 1, 'n_units_l0': 120, 'dropout_l0': 0.46766713846047553, 'optimizer': 'Adam', 'lr': 0.002881282393924672}. Best is trial 42 with value: 0.83828125.\u001b[0m\n",
            "\u001b[32m[I 2023-04-15 04:12:16,666]\u001b[0m Trial 89 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-04-15 04:12:17,612]\u001b[0m Trial 90 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-04-15 04:12:26,883]\u001b[0m Trial 91 finished with value: 0.83203125 and parameters: {'n_layers': 1, 'n_units_l0': 102, 'dropout_l0': 0.4452828213041525, 'optimizer': 'Adam', 'lr': 0.004093758126810998}. Best is trial 42 with value: 0.83828125.\u001b[0m\n",
            "\u001b[32m[I 2023-04-15 04:12:27,849]\u001b[0m Trial 92 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-04-15 04:12:37,474]\u001b[0m Trial 93 finished with value: 0.81796875 and parameters: {'n_layers': 1, 'n_units_l0': 104, 'dropout_l0': 0.45978179676558323, 'optimizer': 'Adam', 'lr': 0.00521396870442493}. Best is trial 42 with value: 0.83828125.\u001b[0m\n",
            "\u001b[32m[I 2023-04-15 04:12:38,425]\u001b[0m Trial 94 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-04-15 04:12:39,358]\u001b[0m Trial 95 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-04-15 04:12:48,826]\u001b[0m Trial 96 finished with value: 0.81875 and parameters: {'n_layers': 1, 'n_units_l0': 128, 'dropout_l0': 0.47388504406788534, 'optimizer': 'Adam', 'lr': 0.0025288595078219113}. Best is trial 42 with value: 0.83828125.\u001b[0m\n",
            "\u001b[32m[I 2023-04-15 04:12:49,810]\u001b[0m Trial 97 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-04-15 04:12:59,374]\u001b[0m Trial 98 finished with value: 0.82109375 and parameters: {'n_layers': 1, 'n_units_l0': 114, 'dropout_l0': 0.44513461163401497, 'optimizer': 'Adam', 'lr': 0.0020842444510760197}. Best is trial 42 with value: 0.83828125.\u001b[0m\n",
            "\u001b[32m[I 2023-04-15 04:13:01,827]\u001b[0m Trial 99 pruned. \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Study statistics: \n",
            "  Number of finished trials:  100\n",
            "  Number of pruned trials:  51\n",
            "  Number of complete trials:  49\n",
            "Best trial:\n",
            "  Value:  0.83828125\n",
            "  Params: \n",
            "    n_layers: 1\n",
            "    n_units_l0: 86\n",
            "    dropout_l0: 0.46656652538027943\n",
            "    optimizer: Adam\n",
            "    lr: 0.0029311440561004105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "02-itigAFzHW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}